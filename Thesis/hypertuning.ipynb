{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the imports\n",
    "import os, os.path\n",
    "import qml\n",
    "import math\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from qml.kernels import gaussian_kernel\n",
    "from qml.kernels import laplacian_kernel\n",
    "from qml.math import cho_solve\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import statistics\n",
    "from qml.kernels import matern_kernel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_benzene=np.load(\"Binaries/coulomb_matrix_list_tdm.npy\")\n",
    "y_benzene = np.loadtxt(\"InitialData/D_01.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from qml.math import cho_solve\n",
    "def krr_qml(x_train,x_test,y_train,y_test,sigma):\n",
    "    K=gaussian_kernel(x_train,x_train,sigma=sigma)\n",
    "    K[np.diag_indices_from(K)] += 1e-9\n",
    "    alpha = cho_solve(K, y_train)\n",
    "    Ks=gaussian_kernel(x_train,x_test,sigma)\n",
    "    y_predict=np.dot(alpha,Ks) \n",
    "    return np.mean(np.abs(y_predict - y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Sigma value: 4901\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x_benzene, y_benzene[:,2], shuffle=False, train_size=0.8)\n",
    "\n",
    "sigmas= range(1, 5000, 100)\n",
    "\n",
    "def hypertuning(sigmas):\n",
    "    \"\"\"\n",
    "    Hypertuning function which finds the optimal kernel width for a given dataset. The function minimises the MAE of KRR.\n",
    "\n",
    "    Parameters:\n",
    "        sigmas(range): The kernel widths to try. \n",
    "        \n",
    "    Returns:\n",
    "        optimal_sigma(int): The kernel width with the lowest MAE.\n",
    "    \"\"\"\n",
    "    min_mae=np.inf\n",
    "    optimal_sigma=None\n",
    "    for sigma_val in sigmas:\n",
    "        mae_templ = krr_qml(X_train1[:200],X_test1[:-50],y_train1[:200],y_test1[:-50],sigma_val)\n",
    "        if mae_templ < min_mae:\n",
    "            min_mae = mae_templ\n",
    "            optimal_sigma = sigma_val\n",
    "    return optimal_sigma    \n",
    "   \n",
    "\n",
    "print(\"Optimal Sigma value:\",hypertuning(sigmas))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
