{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qml.kernels import gaussian_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from qml.math import cho_solve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qml.math import cho_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(27)\n",
    "\n",
    "def f1(x):\n",
    "    return np.sin(x[:, 0]) + np.cos(x[:, 1]) + np.exp(x[:, 2]) + np.sin(x[:, 3]) + np.cos(x[:, 4])\n",
    "def f2(x):\n",
    "    return np.cos(x[:, 0]) + np.exp(x[:, 1]) + np.sin(x[:, 2]) + np.cos(x[:, 3]) + np.exp(x[:, 4])\n",
    "def f3(x):\n",
    "    return np.sin(x[:, 0]) + np.exp(x[:, 1]) + np.cos(x[:, 2]) + np.sin(x[:, 3]) + np.exp(x[:, 4])\n",
    "# Generate 3000 samples of 5 dimensional input X with random numbers between 0 and 1\n",
    "X = np.random.rand(3000, 5)\n",
    "\n",
    "# Generate 3 dimensional output Y using output functions\n",
    "Y = np.zeros((3000, 3))\n",
    "Y[:, 0] = f1(X)\n",
    "Y[:, 1] = f2(X)\n",
    "Y[:, 2] = f3(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def krr_qml(x_train,x_test,y_train,y_test,sigma):\n",
    "    K=gaussian_kernel(x_train,x_train,sigma=sigma)\n",
    "    K[np.diag_indices_from(K)] += 1e-9\n",
    "    alpha = cho_solve(K, y_train)\n",
    "    Ks=gaussian_kernel(x_train,x_test,sigma)\n",
    "    y_predict=np.dot(alpha,Ks) \n",
    "    return np.mean(np.abs(y_predict - y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Sigma value for component 1: 100\n",
      "Optimal Sigma value for component 2: 100\n",
      "Optimal Sigma value for component 3: 100\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X, Y, shuffle=False, train_size=0.8)\n",
    "\n",
    "sigmas = range(0, 5001, 100)\n",
    "\n",
    "def hypertuning(sigmas):\n",
    "    \"\"\"\n",
    "    Hypertuning function which finds the optimal kernel width for a given dataset. The function minimises the MAE of KRR.\n",
    "\n",
    "    Parameters:\n",
    "        sigmas(range): The kernel widths to try. \n",
    "        \n",
    "    Returns:\n",
    "        optimal_sigma(int): The kernel width with the lowest MAE.\n",
    "    \"\"\"\n",
    "    min_mae = np.inf\n",
    "    optimal_sigma = None\n",
    "    for sigma_val in sigmas:\n",
    "        mae_templ = krr_qml(X_train1[0:200], X_test1[0:50], Y_train[0:200], Y_test[0:50], sigma_val)\n",
    "        if mae_templ < min_mae:\n",
    "            min_mae = mae_templ\n",
    "            optimal_sigma = sigma_val\n",
    "    return optimal_sigma     \n",
    "\n",
    "optimal_sigmas = []\n",
    "for i in range(3):\n",
    "    Y_train = Y_train1[:,i]\n",
    "    Y_test = Y_test1[:,i]\n",
    "    optimal_sigma = hypertuning(sigmas)\n",
    "    optimal_sigmas.append(optimal_sigma)\n",
    "    print(f\"Optimal Sigma value for component {i+1}: {optimal_sigma}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
